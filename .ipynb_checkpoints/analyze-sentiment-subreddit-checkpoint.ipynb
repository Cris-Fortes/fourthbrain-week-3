{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=”false” ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Reddit Data using Reddit API</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( 🤗 the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the session, you will "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- know how to work with APIs\n",
    "- feel more comfortable navigating thru documentation, even inspecting the source code\n",
    "- understand what a `pipeline` object is in HuggingFace\n",
    "- perform sentiment analysis using `pipeline`\n",
    "- run a python script in command line and get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At the end of each task, commit* the work into the repository you created before the assignment\n",
    "- After completing all three tasks, make sure to push the notebook containing all code blocks and output cells to your repository you created before the assignment\n",
    "- Submit the link to the notebook in Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\***NEVER** commit a notebook displaying errors unless it is instructed otherwise. However, commit often; recall git ABC = **A**lways **B**e **C**ommitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task I: Instantiate a Reddit API Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first task is to instantiate a Reddit API object using [PRAW](https://praw.readthedocs.io/en/stable/), through which you will retrieve data. PRAW is a wrapper for [Reddit API](https://www.reddit.com/dev/api) that makes interacting with the Reddit API easier unless you are already an expert of [`requests`](https://docs.python-requests.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Please ensure you've ran all the cells in the `imports.ipynb`, located [here](https://github.com/FourthBrain/MLE-8/blob/main/assignments/week-3-analyze-sentiment-subreddit/imports.ipynb), to make sure you have all the required packages for today's assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2. Create a new app on Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new app on Reddit and save secret tokens; refer to [post in medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Create a Reddit account if you don't have one, log into your account.\n",
    "- To access the API, we need create an app. Slight updates, on the website, you need to navigate to `preference` > `app`, or click [this link](https://www.reddit.com/prefs/apps) and scroll all the way down. \n",
    "- Click to create a new app, fill in the **name**, choose `script`, fill in  **description** and **redirect uri** ( The redirect URI is where the user is sent after they've granted OAuth access to your application (more info [here](https://github.com/reddit-archive/reddit/wiki/OAuth2)) For our purpose, you can enter some random url, e.g., www.google.com; as shown below.\n",
    "\n",
    "\n",
    "    <img src=\"https://miro.medium.com/max/700/1*lRBvxpIe8J2nZYJ6ucMgHA.png\" width=\"500\"/>\n",
    "- Jot down `client_id` (left upper corner) and `client_secret` \n",
    "\n",
    "    NOTE: CLIENT_ID refers to 'personal use script\" and CLIENT_SECRET to secret.\n",
    "    \n",
    "    <div>\n",
    "    <img src=\"https://miro.medium.com/max/700/1*7cGAKth1PMrEf2sHcQWPoA.png\" width=\"300\"/>\n",
    "    </div>\n",
    "\n",
    "- Create `secrets_reddit.py` in the same directory with this notebook, fill in `client_id` and `secret_id` obtained from the last step. We will need to import those constants in the next step.\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = \"client_id\"\n",
    "    REDDIT_API_CLIENT_SECRET = \"secret_id\"\n",
    "    REDDIT_API_USER_AGENT = \"any string except bot; ex. My User Agent\"\n",
    "    ```\n",
    "- Add `secrets_reddit.py` to your `.gitignore` file if not already done. NEVER push credentials to a repo, private or public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Instantiate a `Reddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you are ready to create a read-only `Reddit` instance. Refer to [documentation](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import secrets_reddit\n",
    "\n",
    "# Create a Reddit object which allows us to interact with the Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id = secrets_reddit.REDDIT_API_CLIENT_ID,\n",
    "    client_secret = secrets_reddit.REDDIT_API_CLIENT_SECRET,\n",
    "    user_agent = secrets_reddit.REDDIT_API_USER_AGENT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<praw.reddit.Reddit object at 0x7ff04877a160>\n"
     ]
    }
   ],
   "source": [
    "print(reddit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "```<praw.reddit.Reddit object at 0x10f8a0ac0>```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Instantiate a `subreddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly, create a `subreddit` object for your favorite subreddit and inspect the object. The expected outputs you will see are from `r/machinelearning` unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(\"machinelearning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the display name of the subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machinelearning\n"
     ]
    }
   ],
   "source": [
    "print(subreddit.display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    machinelearning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How about its title, is it different from the display name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning\n"
     ]
    }
   ],
   "source": [
    "print(subreddit.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    Machine Learning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print out the description of the subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
      "--------\n",
      "+[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
      "--------\n",
      "+[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
      "--------\n",
      "+[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
      "--------\n",
      "+[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ANews)\n",
      "--------\n",
      "***[@slashML on Twitter](https://twitter.com/slashML)***\n",
      "--------\n",
      "***[Chat with us on Slack](https://join.slack.com/t/rml-talk/shared_invite/enQtNjkyMzI3NjA2NTY2LWY0ZmRjZjNhYjI5NzYwM2Y0YzZhZWNiODQ3ZGFjYmI2NTU3YjE1ZDU5MzM2ZTQ4ZGJmOTFmNWVkMzFiMzVhYjg)***\n",
      "--------\n",
      "**Beginners:**\n",
      "--------\n",
      "Please have a look at [our FAQ and Link-Collection](http://www.reddit.com/r/MachineLearning/wiki/index)\n",
      "\n",
      "[Metacademy](http://www.metacademy.org) is a great resource which compiles lesson plans on popular machine learning topics.\n",
      "\n",
      "For Beginner questions please try /r/LearnMachineLearning , /r/MLQuestions or http://stackoverflow.com/\n",
      "\n",
      "For career related questions, visit /r/cscareerquestions/\n",
      "\n",
      "--------\n",
      "\n",
      "[Advanced Courses (2016)](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses?st=isz2lqdk&sh=56c58cd6)\n",
      "\n",
      "[Advanced Courses (2020)](https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/)\n",
      "\n",
      "--------\n",
      "**AMAs:**\n",
      "\n",
      "[Pluribus Poker AI Team 7/19/2019](https://www.reddit.com/r/MachineLearning/comments/ceece3/ama_we_are_noam_brown_and_tuomas_sandholm/)\n",
      "\n",
      "[DeepMind AlphaStar team (1/24//2019)](https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/)\n",
      "\n",
      "[Libratus Poker AI Team (12/18/2017)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/7jn12v/ama_we_are_noam_brown_and_professor_tuomas/)\n",
      "\n",
      "[DeepMind AlphaGo Team (10/19/2017)](https://www.reddit.com/r/MachineLearning/comments/76xjb5/ama_we_are_david_silver_and_julian_schrittwieser/)\n",
      "\n",
      "[Google Brain Team (9/17/2017)](https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/)\n",
      "\n",
      "[Google Brain Team (8/11/2016)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/)\n",
      "\n",
      "[The MalariaSpot Team (2/6/2016)](https://www.reddit.com/r/MachineLearning/comments/4m7ci1/ama_the_malariaspot_team/)\n",
      "\n",
      "[OpenAI Research Team (1/9/2016)](http://www.reddit.com/r/MachineLearning/comments/404r9m/ama_the_openai_research_team/)\n",
      "\n",
      "[Nando de Freitas (12/26/2015)](http://www.reddit.com/r/MachineLearning/comments/3y4zai/ama_nando_de_freitas/)\n",
      "\n",
      "[Andrew Ng and Adam Coates (4/15/2015)](http://www.reddit.com/r/MachineLearning/comments/32ihpe/ama_andrew_ng_and_adam_coates/)\n",
      "\n",
      "[Jürgen Schmidhuber (3/4/2015)](http://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/)\n",
      "\n",
      "[Geoffrey Hinton (11/10/2014)]\n",
      "(http://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/)\n",
      "\n",
      "[Michael Jordan (9/10/2014)](http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/)\n",
      "\n",
      "[Yann LeCun (5/15/2014)](http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/)\n",
      "\n",
      "[Yoshua Bengio (2/27/2014)](http://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio/)\n",
      "\n",
      "--------\n",
      "Related Subreddit :\n",
      "\n",
      "* [LearnMachineLearning](http://www.reddit.com/r/LearnMachineLearning)\n",
      "\n",
      "* [Statistics](http://www.reddit.com/r/statistics)\n",
      "\n",
      "* [Computer Vision](http://www.reddit.com/r/computervision)\n",
      "\n",
      "* [Compressive Sensing](http://www.reddit.com/r/CompressiveSensing/)\n",
      "\n",
      "* [NLP] (http://www.reddit.com/r/LanguageTechnology)\n",
      "\n",
      "* [ML Questions] (http://www.reddit.com/r/MLQuestions)\n",
      "\n",
      "* /r/MLjobs and /r/BigDataJobs\n",
      "\n",
      "* /r/datacleaning\n",
      "\n",
      "* /r/DataScience\n",
      "\n",
      "* /r/scientificresearch\n",
      "\n",
      "* /r/artificial\n"
     ]
    }
   ],
   "source": [
    "print(subreddit.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "    **[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
    "    --------\n",
    "    +[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
    "    --------\n",
    "    +[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
    "    --------\n",
    "    +[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
    "    --------\n",
    "    +[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task II: Parse comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1. Top Posts of All Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Find titles of top 10 posts of **all time** from your favorite subreddit. Refer to [Obtain Submission Instances from a Subreddit Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)) if necessary. Verify if the titles match what you read on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# try run this line, what do you see? press q once you are done\n",
    "?subreddit.top \n",
    "# An explanation of this \"method\" called subreddit.top including which\n",
    "# paramaters can be used and that it is a ListingGenerator.\n",
    "# Which will come in handy down below in the question about \n",
    "# the top 10 posts of this week! Thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Project] From books to presentations in 10s with AR + ML\n",
      "[D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
      "[R] First Order Motion Model applied to animate paintings\n",
      "[N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
      "[D] This AI reveals how much time politicians stare at their phone at work\n",
      "[D] Types of Machine Learning Papers\n",
      "[D] The machine learning community has a toxicity problem\n",
      "I made a robot that punishes me if it detects that if I am procrastinating on my assignments [P]\n",
      "[Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
      "[P] Using oil portraits and First Order Model to bring the paintings back to life\n"
     ]
    }
   ],
   "source": [
    "for submission in subreddit.top(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details> <summary>Expected output:</summary>\n",
    "\n",
    "    [Project] From books to presentations in 10s with AR + ML\n",
    "    [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
    "    [R] First Order Motion Model applied to animate paintings\n",
    "    [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
    "    [D] This AI reveals how much time politicians stare at their phone at work\n",
    "    [D] Types of Machine Learning Papers\n",
    "    [D] The machine learning community has a toxicity problem\n",
    "    [Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
    "    [P] Using oil portraits and First Order Model to bring the paintings back to life\n",
    "    [D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG)    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2. Top 10 Posts of This Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What are the titles of the top 10 posts of **this week** from your favorite subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P] Simple fastai based face restoration project, GitHub link in comments.\n",
      "[R] SIMPLERECON — 3D Reconstruction without 3D Convolutions — 73ms per frame !\n",
      "[P] pytorch's Newest nvFuser, on Stable Diffusion to make your favorite diffusion model sample 2.5 times faster (compared to full precision) and 1.5 times faster (compared to half-precision)\n",
      "[P] Cozy Auto Texture - A Blender add-on that allows you to generate free textures with Stable Diffusion\n",
      "[D] How do you find your collaborators in AI research?\n",
      "[P] Teach new concepts to Stable Diffusion with 3-5 images only - and browse a library of learned concepts to use with a gradio demo in colab\n",
      "[P] Stable Diffusion web UI with Outpainting, Inpainting, Prompt matrix, Upscale, Textual Inversion and many more features\n",
      "[N] NVIDIA Hopper Sweeps AI Inference Benchmarks in MLPerf Debut\n",
      "[D] Most Popular AI Research August 2022 - Ranked By Twitter Likes\n",
      "[N] Stable Diffusion Image Variations released, allows you to do variations like DALLE-2\n"
     ]
    }
   ],
   "source": [
    "for submission in subreddit.top(limit=10, time_filter=\"week\"):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details><summary>Expected output:</summary>\n",
    "\n",
    "    [N] Ian Goodfellow, Apple’s director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said “I believe strongly that more flexibility would have been the best policy for my team.” He was likely the company’s most cited ML expert.\n",
    "    [R][P] Thin-Plate Spline Motion Model for Image Animation + Gradio Web Demo\n",
    "    [P] I’ve been trying to understand the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple’s version of MobileNet, and more directly on your phone's camera roll.\n",
    "    [R] Meta is releasing a 175B parameter language model\n",
    "    [N] Hugging Face raised $100M at $2B to double down on community, open-source & ethics\n",
    "    [P] T-SNE to view and order your Spotify tracks\n",
    "    [D] : HELP Finding a Book - A book written for Google Engineers about foundational Math to support ML\n",
    "    [R] Scaled up CLIP-like model (~2B) shows 86% Zero-shot on Imagenet\n",
    "    [D] Do you use NLTK or Spacy for text preprocessing?\n",
    "    [D] Democratizing Diffusion Models - LDMs: High-Resolution Image Synthesis with Latent Diffusion Models, a 5-minute paper summary by Casual GAN Papers\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "Check out what other attributes the `praw.models.Submission` class has in the [docs](https://praw.readthedocs.io/en/stable/code_overview/models/submission.html). \n",
    "\n",
    "1. After having a chance to look through the docs, is there any other information that you might want to extract? How might this additional data help you?\n",
    "\n",
    "Write a sample piece of code below extracting three additional pieces of information from the submission below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: cyrildiagne | Title: [Project] From books to presentations in 10s with AR + ML | Score: 7436 | Number of comments: 184 | URL: https://v.redd.it/v492uoheuxx41\n",
      "\n",
      "Author: TheInsaneApp | Title: [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition | Score: 5650 | Number of comments: 128 | URL: https://v.redd.it/25nxi9ojfha61\n",
      "\n",
      "Author: programmerChilli | Title: [R] First Order Motion Model applied to animate paintings | Score: 4665 | Number of comments: 110 | URL: https://v.redd.it/rlmmjm1q5wu41\n",
      "\n",
      "Author: TheInsaneApp | Title: [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this | Score: 4578 | Number of comments: 230 | URL: https://v.redd.it/ikd5gjlbi8k61\n",
      "\n",
      "Author: TheInsaneApp | Title: [D] This AI reveals how much time politicians stare at their phone at work | Score: 4344 | Number of comments: 228 | URL: https://i.redd.it/34sgziebfia71.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here is what I did. I went for the top 5 of all time posts/submissions\n",
    "# on the Machine Learning (ML) subreddit and then added in this order their\n",
    "# author, title, score (which mimics the number of upvotes), number of\n",
    "# comments and finally the URL in case I wanted to quickly access and\n",
    "# read them.\n",
    "# An interesting (and unexpected) insight for me is that currently the \n",
    "# author \"TheInsaneApp\" has the #2, #4 and #5 ML posts of all time!\n",
    "\n",
    "for submission in subreddit.top(limit=5):\n",
    "\n",
    "    print(\"Author:\", submission.author, \"|\", \"Title:\", \n",
    "          submission.title, \"|\", \"Score:\", submission.score, \n",
    "          \"|\", \"Number of comments:\", submission.num_comments,\n",
    "         \"|\", \"URL:\", submission.url)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "2. Is there any information available that might be a concern when it comes to Ethical Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially yes. As we've just seen, a lot of the data on Reddit\n",
    "# is public and easily accessible and analyzable via APIs.\n",
    "# That in itself in my view poses two possible risks:\n",
    "# 1) That users inadvertently and naively post private information\n",
    "# about themselves that they clearly shouldn't and\n",
    "# 2) That confidential, classified and/or intellectual property- (IP)\n",
    "# protected information is relayed as if it were public information\n",
    "# even when it clearly isn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3. Comment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add comments to the code block below to describe what each line of the code does (Refer to [Obtain Comment Instances Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html) when necessary). The code is adapted from [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
    "\n",
    "The purpose is \n",
    "1. to understand what the code is doing \n",
    "2. start to comment your code whenever it is not self-explantory if you have not (others will thank you, YOU will thank you later 😊) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 575 ms, sys: 35.7 ms, total: 611 ms\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# Create variable \"top_comments\" and assign an empty list to it.\n",
    "top_comments = []\n",
    "\n",
    "# As before, we assigned the Machine Learning subreddit to the subreddit\n",
    "# variable\n",
    "subreddit = reddit.subreddit(\"machinelearning\")\n",
    "\n",
    "# Iterate through every submission of the top 10 comments in the subreddit\n",
    "for submission in subreddit.top(limit=10):\n",
    "    # Iterate through every top level comment across all submissions' comments\n",
    "    for top_level_comment in submission.comments:\n",
    "        # If a top level comment is classed as \"MoreComments\", just ignore/skip it\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # Append (i.e. add) the body of all the top level comments to \n",
    "        # the currently list/variable called \"top_comments\n",
    "        top_comments.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 4. Inspect Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How many comments did you extract from the last step? Examine a few comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_comments)  # the answer may vary 693 for r/machinelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hahahaha. \\n\\nBottom left corner is why I left ML reasearch. What was ridiculous was CVPR actually accepting the <1% improvements.',\n",
       " 'Well, I found some statements here are actually incorrect or superficial. For example, you cannot simply draw a conclusion based on a single BERT paper without much context, and do not consider a lot of confounding factors (e.g. its results are much better than others). If you just want to reason by a single example, why not look at the two concurrent papers of VAE, [one](https://arxiv.org/abs/1312.6114) from Universiteit van Amsterdam which is cited \\\\~10K times, [the other](https://arxiv.org/abs/1401.4082) from Deepmind which is cited <3K. Can you draw an opposite conclusion from this?',\n",
       " \"That's awesome dude! I love it.\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "[random.choice(top_comments) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> <summary>Some of the comments from `r/machinelearning` subreddit are:</summary>\n",
    "\n",
    "    ['Awesome visualisation',\n",
    "    'Similar to a stack or connected neurons.',\n",
    "    'Will this Turing pass the Turing Test?']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "3. After having a chance to review a few samples of 5 comments from the subreddit, what can you say about the data? \n",
    "\n",
    "HINT: Think about the \"cleanliness\" of the data, the content of the data, think about what you're trying to do - how does this data line up with your goal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My first reaction is to think that the \"data quality\" is uneven.\n",
    "# In other words, and remembering this is a voluntary, most often \n",
    "# anonymous forum of people talking about machine learning,\n",
    "# there is extra helpful stuff but also day-to-day pleasantries\n",
    "# not to mention low-value content that might not even be directly \n",
    "# related to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5. Extract Top Level Comment from Subreddit `TSLA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Write your code to extract top level comments from the top 10 topics of a time period, e.g., year, from subreddit `TSLA` and store them in a list `top_comments_tsla`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85.8 ms, sys: 8.7 ms, total: 94.5 ms\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# Create variable \"top_comments_tsla\" and assign an empty list to it.\n",
    "top_comments_tsla = []\n",
    "\n",
    "# Assign the TSLA subreddit to the subreddit variable\n",
    "subreddit = reddit.subreddit(\"TSLA\")\n",
    "\n",
    "# Iterate through every submission of the top 10 comments\n",
    "# of this week in the subreddit\n",
    "for submission in subreddit.top(limit=10, time_filter=\"week\"):\n",
    "    # Iterate through every top level comment across all submission's comments\n",
    "    for top_level_comment in submission.comments:\n",
    "        # If a top level comment is classed as \"MoreComments\", just ignore/skip it\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # Append (i.e. add to the end) the body of all the top level comments to \n",
    "        # the currently list/variable called top_comments_tsla\n",
    "        top_comments_tsla.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_comments_tsla) # Expected: 174 for r/machinelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$169.04 X70', '$207/ 1004 shares', '165@$114 I think']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[random.choice(top_comments_tsla) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Some of the comments from `r/TSLA` subreddit:</summary>\n",
    "\n",
    "    ['I bought puts',\n",
    "    '100%',\n",
    "    'Yes. And I’m bag holding 1200 calls for Friday and am close to throwing myself out the window']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "4. Now that you've had a chance to review another subreddits comments, do you see any differences in the kinds of comments either subreddit has - and how might this relate to bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This subreddit seems to be even more focused than the Machine Learning one.\n",
    "# It's largely about company- and stock-related information.\n",
    "# I saw less disperson here. It's, again, much more focused.\n",
    "# I've also noticed the ML one has 2.5 million members and this one\n",
    "# fewer than 14K. This in turn produce fewer comments since there is \n",
    "# less activity in absolute terms.\n",
    "# Regarding bias, the content is not representative of all the possible\n",
    "# Tesla investors of the world, obviously. It represents the group\n",
    "# of folks who chose to join this subreddit/forum.\n",
    "# Thus \"buyer\" (in this case meaning reader) beware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task III: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us analyze the sentiment of comments scraped from `r/TSLA` using a pre-trained HuggingFace model to make the inference. Take a [Quick tour](https://huggingface.co/docs/transformers/quicktour). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Import `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2. Create a Pipeline to Perform Task \"sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Get one comment from list `top_comments_tsla` from Task II - 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comment = random.choice(top_comments_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£103\n"
     ]
    }
   ],
   "source": [
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example comment is: `'Bury Burry!!!!!'`. Print out what you get. For reproducibility, use the same comment in the next step; consider setting a seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Make Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9425747394561768}]\n"
     ]
    }
   ],
   "source": [
    "sentiment = sentiment_model(\"comment\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the type of the output `sentiment`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [{'label': 'POSITIVE', 'score': 0.9425747394561768}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment: £103\n",
      "Predicted Label is POSITIVE and the score is 0.943\n"
     ]
    }
   ],
   "source": [
    "print(f'The comment: {comment}')\n",
    "print(f'Predicted Label is {sentiment[0][\"label\"]} and the score is {sentiment[0][\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example comment, the output is:\n",
    "\n",
    "    The comment: Bury Burry!!!!!\n",
    "    Predicted Label is NEGATIVE and the score is 0.989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🖥️❓ Model Question:\n",
    "\n",
    "1. What does the score represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability or confidence level (from 0 to 1) that the sentiment prediction (positive or negative) is accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task IV: Put All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull all the piece together, create a simple script that does \n",
    "\n",
    "- get the subreddit\n",
    "- get comments from the top posts for given subreddit\n",
    "- run sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you complete the code, running the following block writes the code into a new Python script and saves it as `top_tlsa_comment_sentiment.py` under the same directory with the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_tlsa_comment_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_tlsa_comment_sentiment.py\n",
    "\n",
    "import secrets_reddit\n",
    "import random\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "from praw import Reddit\n",
    "from praw.models.reddit.subreddit import Subreddit\n",
    "from praw.models import MoreComments\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def get_subreddit(display_name:str) -> Subreddit:\n",
    "    \"\"\"Get subreddit object from display name\n",
    "\n",
    "    Args:\n",
    "        display_name (str): [description]\n",
    "\n",
    "    Returns:\n",
    "        Subreddit: [description]\n",
    "    \"\"\"    \n",
    "    reddit = Reddit(\n",
    "        client_id = secrets_reddit.REDDIT_API_CLIENT_ID,\n",
    "        client_secret = secrets_reddit.REDDIT_API_CLIENT_SECRET,\n",
    "        user_agent = secrets_reddit.REDDIT_API_USER_AGENT,\n",
    "        )\n",
    "    subreddit = reddit.subreddit(\"display_name\")\n",
    "    return subreddit\n",
    "\n",
    "def get_comments(subreddit:Subreddit, limit:int=3) -> List[str]:\n",
    "    \"\"\" Get comments from subreddit\n",
    "\n",
    "    Args:\n",
    "        subreddit (Subreddit): [description]\n",
    "        limit (int, optional): [description]. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of comments\n",
    "    \"\"\"\n",
    "    top_comments = []\n",
    "    for submission in subreddit.top(limit=limit):\n",
    "        for top_level_comment in submission.comments:\n",
    "            if isinstance(top_level_comment, MoreComments):\n",
    "                continue\n",
    "            top_comments.append(top_level_comment.body)\n",
    "    return top_comments\n",
    "\n",
    "def run_sentiment_analysis(comment:str) -> Dict:\n",
    "    \"\"\"Run sentiment analysis on comment using default distilbert model\n",
    "    \n",
    "    Args:\n",
    "        comment (str): [description]\n",
    "        \n",
    "    Returns:\n",
    "        str: Sentiment analysis result\n",
    "    \"\"\"\n",
    "    sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "    sentiment = sentiment_model(comment)\n",
    "    return sentiment[0]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    subreddit = get_subreddit(\"TSLA\")\n",
    "    comments = get_comments(subreddit)\n",
    "    comment = random.choice(comments)\n",
    "    sentiment = run_sentiment_analysis(comment)\n",
    "    \n",
    "    print(f'The comment: {comment}')\n",
    "    print(f'Predicted Label is {sentiment[\"label\"]} and the score is {sentiment[\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "The comment: What\n",
      "Predicted Label is POSITIVE and the score is 0.994\n"
     ]
    }
   ],
   "source": [
    "!python top_tlsa_comment_sentiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Expected output:</summary>\n",
    "\n",
    "    No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "    The comment: When is DOGE flying\n",
    "    Predicted Label is POSITIVE and the score is 0.689\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "5. Is the subreddit active? About how many posts or threads per day? How could you find this information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TSLA subreddit is somewhat active. As a quick reference,\n",
    "# I pulled up the top comments in the last month (see below code and output)\n",
    "# and found a total of 52 submissions i.e. fewer than 2 a day, on average.\n",
    "# Furthermore the score and number of comments per submission are not\n",
    "# particularly high either.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: IhateFARTINGatWORK | Title: Happy Split day everyone.. | Score: 38 | Number of comments: 37 | URL: https://www.reddit.com/r/TSLA/comments/wwjg5g/happy_split_day_everyone/\n",
      "\n",
      "Author: droneauto | Title: Tesla says Autopilot is preventing ~40 crashes per day from wrong pedal errors alone | Score: 28 | Number of comments: 6 | URL: https://www.reddit.com/r/TSLA/comments/wuwum2/tesla_says_autopilot_is_preventing_40_crashes_per/\n",
      "\n",
      "Author: localbrada | Title: Tesla battery fire and crash were faked by insuranc | Score: 24 | Number of comments: 2 | URL: https://electrek.co/2022/08/30/tesla-battery-fire-crash-faked-insurance-company-bizarre-showcase/\n",
      "\n",
      "Author: wewewawa | Title: Tesla (TSLA) is facing ‘unprecedented demand’ | Score: 25 | Number of comments: 4 | URL: https://electrek.co/2022/08/31/tesla-tsla-facing-unprecedented-demand/\n",
      "\n",
      "Author: localbrada | Title: Tesla Sues to Sell Cars Directly to Consumers in Louisiana | Score: 24 | Number of comments: 5 | URL: https://www.wsj.com/articles/tesla-sues-to-sell-cars-directly-to-consumers-in-louisiana-11661806328\n",
      "\n",
      "Author: _myke | Title: July '18: Tesla says GF Shanghai to hit 500k cars/yr by '22, '23. Now at 1,200k rate for Sept '22 | Score: 21 | Number of comments: 0 | URL: https://www.usatoday.com/story/money/cars/2018/07/10/tesla-china-factory-tariffs/770651002/\n",
      "\n",
      "Author: droneauto | Title: Tesla (TSLA) is facing ‘unprecedented demand’ | Score: 21 | Number of comments: 6 | URL: https://www.reddit.com/r/TSLA/comments/x2n8gf/tesla_tsla_is_facing_unprecedented_demand/\n",
      "\n",
      "Author: siennasolo | Title: Thought I'd quickly share my story with Tesla and the life lesson I've gained. | Score: 22 | Number of comments: 5 | URL: https://www.reddit.com/r/TSLA/comments/x09ome/thought_id_quickly_share_my_story_with_tesla_and/\n",
      "\n",
      "Author: wewewawa | Title: Tesla plans a ‘license to print money’ aka lithium refining factory in Texas | Score: 19 | Number of comments: 1 | URL: https://electrek.co/2022/09/09/tesla-license-to-print-money-lithium-refining-factory-texas/\n",
      "\n",
      "Author: Practical-Package-42 | Title: Stock split displaying incorrect? | Score: 21 | Number of comments: 30 | URL: https://www.reddit.com/r/TSLA/comments/wx8k11/stock_split_displaying_incorrect/\n",
      "\n",
      "Author: wewewawa | Title: Tesla virtual power plant is rocketing up, reaches 50 MW | Score: 18 | Number of comments: 5 | URL: https://electrek.co/2022/09/02/tesla-virtual-power-plant-growing/\n",
      "\n",
      "Author: wewewawa | Title: A Tesla burst into flames during a crash test. Organizer admitted it was staged | Score: 18 | Number of comments: 4 | URL: https://www.npr.org/2022/09/02/1120623318/a-tesla-burst-into-flames-during-a-crash-test-the-organizer-admitted-it-was-stag\n",
      "\n",
      "Author: localbrada | Title: First Green Day in September | Score: 17 | Number of comments: 4 | URL: https://www.reddit.com/r/TSLA/comments/x7l6ty/first_green_day_in_september/\n",
      "\n",
      "Author: AssumptionDear4644 | Title: Upcoming stock split | Score: 15 | Number of comments: 21 | URL: https://www.reddit.com/r/TSLA/comments/wrp6nk/upcoming_stock_split/\n",
      "\n",
      "Author: siennasolo | Title: what's your purchase price now after the split? | Score: 13 | Number of comments: 47 | URL: https://www.reddit.com/r/TSLA/comments/x7yqev/whats_your_purchase_price_now_after_the_split/\n",
      "\n",
      "Author: TonyLiberty | Title: Tesla stock is set to rip higher, analyst says after visiting Germany Gigafactory | Score: 13 | Number of comments: 2 | URL: https://finance.yahoo.com/news/tesla-stock-higher-analyst-projects-162251174.html\n",
      "\n",
      "Author: Estos-Huevos210 | Title: Bullish price prediction: 1000 before split. | Score: 15 | Number of comments: 26 | URL: https://www.reddit.com/r/TSLA/comments/wnw9ov/bullish_price_prediction_1000_before_split/\n",
      "\n",
      "Author: localbrada | Title: Tesla supplier Panasonic plans additional $4 bln U.S. EV battery plant - WSJ | Score: 12 | Number of comments: 1 | URL: https://www.kitco.com/news/2022-08-26/Tesla-supplier-Panasonic-plans-additional-4-bln-U-S-EV-battery-plant-WSJ.html\n",
      "\n",
      "Author: TonyLiberty | Title: Tesla (TSLA) is facing ‘unprecedented demand’ | Score: 12 | Number of comments: 4 | URL: https://electrek.co/2022/08/31/tesla-tsla-facing-unprecedented-demand/\n",
      "\n",
      "Author: wewewawa | Title: Tesla Cash Hoard Could Hit Half-Trillion by 2030. What That Money Could Do. | Score: 12 | Number of comments: 0 | URL: https://www.barrons.com/articles/tesla-free-cash-flow-51661271533?siteid=yhoof2\n",
      "\n",
      "Author: wewewawa | Title: The Staggering Economics of the Tesla Semi | Score: 12 | Number of comments: 19 | URL: https://www.torquenews.com/14335/staggering-economics-tesla-semi\n",
      "\n",
      "Author: wewewawa | Title: Americans are borrowing at record levels to pay for their expensive cars | Score: 10 | Number of comments: 5 | URL: https://www.cnn.com/2022/08/25/cars/car-price-borrowing/\n",
      "\n",
      "Author: wewewawa | Title: Why Tesla's Stock Split Could Be a Bigger Deal Than Amazon's | Score: 11 | Number of comments: 8 | URL: https://www.fool.com/investing/2022/08/23/why-teslas-stock-split-bigger-deal-than-amazons/\n",
      "\n",
      "Author: wewewawa | Title: Billionaire George Soros Bets on Musk's Tesla and Ford | Score: 11 | Number of comments: 8 | URL: https://www.thestreet.com/technology/billionaire-george-soros-invites-himself-to-elon-musk-and-ford\n",
      "\n",
      "Author: wewewawa | Title: Here’s what Tesla execs told Gigafactory employees Thursday night about plans and management changes | Score: 9 | Number of comments: 2 | URL: https://www.cnbc.com/2022/09/08/tesla-gigafactory-nevada-leaked-audio-meeting-new-leaders-goals.html\n",
      "\n",
      "Author: _myke | Title: New shutdowns in China the cause for TSLA drop today? | Score: 7 | Number of comments: 20 | URL: https://www.reddit.com/r/TSLA/comments/x1qc61/new_shutdowns_in_china_the_cause_for_tsla_drop/\n",
      "\n",
      "Author: Traditional_Good4693 | Title: TSLA month of September outlook. | Score: 8 | Number of comments: 26 | URL: https://www.reddit.com/r/TSLA/comments/wzvvsk/tsla_month_of_september_outlook/\n",
      "\n",
      "Author: wsbt4rd | Title: What's going on? Huge shortening of Model S preorder wait time | Score: 7 | Number of comments: 15 | URL: https://www.reddit.com/r/TSLA/comments/wru438/whats_going_on_huge_shortening_of_model_s/\n",
      "\n",
      "Author: localbrada | Title: Up 1% in After Hours | Score: 7 | Number of comments: 5 | URL: https://www.reddit.com/r/TSLA/comments/x3k6il/up_1_in_after_hours/\n",
      "\n",
      "Author: localbrada | Title: Tesla's Louisiana Fight May Be a Preview for Battles in Other States | Score: 7 | Number of comments: 0 | URL: https://www.barrons.com/articles/tesla-ev-stock-sales-louisiana-51661867528\n",
      "\n",
      "Author: SouthernOar | Title: Triple Shares! | Score: 6 | Number of comments: 3 | URL: https://www.reddit.com/r/TSLA/comments/wwtb2r/triple_shares/\n",
      "\n",
      "Author: Local-Rip9621 | Title: How is everyone managing their positions/trading around the split? | Score: 8 | Number of comments: 34 | URL: https://www.reddit.com/r/TSLA/comments/wr66j1/how_is_everyone_managing_their_positionstrading/\n",
      "\n",
      "Author: droneauto | Title: 2022 Est: 1.6M | Score: 7 | Number of comments: 4 | URL: https://www.reddit.com/r/TSLA/comments/wox9gr/2022_est_16m/\n",
      "\n",
      "Author: jins505 | Title: This or That | Score: 6 | Number of comments: 8 | URL: https://www.reddit.com/r/TSLA/comments/wnqiwd/this_or_that/\n",
      "\n",
      "Author: TonyLiberty | Title: Tesla shortens delivery waiting time for Model Y in China to 4-8 weeks | Score: 6 | Number of comments: 4 | URL: https://www.channelnewsasia.com/business/tesla-shortens-delivery-waiting-time-model-y-china-4-8-weeks-2887076\n",
      "\n",
      "Author: joker3181986 | Title: $FRZA the Tsla of boats | Score: 7 | Number of comments: 3 | URL: https://www.reddit.com/r/TSLA/comments/wp4wvf/frza_the_tsla_of_boats/\n",
      "\n",
      "Author: wewewawa | Title: Companies Are Buying Large Numbers of Carbon Offsets That Don’t Cut Emissions | Score: 5 | Number of comments: 0 | URL: https://www.wsj.com/articles/renewables-carbon-credits-do-not-cut-emissions-united-nations-verra-gold-standard-11662644900\n",
      "\n",
      "Author: localbrada | Title: Tesla puts its vehicles to the test in 122 degree heat in Dubai | Score: 5 | Number of comments: 2 | URL: https://www.teslarati.com/tesla-vehicles-122-degree-heat-dubai/\n",
      "\n",
      "Author: wewewawa | Title: The Funded: VC legend John Doerr regrets not backing 'slightly crazy' Elon Musk | Score: 4 | Number of comments: 2 | URL: https://www.bizjournals.com/sanjose/news/2022/08/24/heres-what-vc-john-doerr-says-was-biggest-miss.html\n",
      "\n",
      "Author: Huge_Outside_3161 | Title: Stock split | Score: 6 | Number of comments: 17 | URL: https://www.reddit.com/r/TSLA/comments/wwkmhi/stock_split/\n",
      "\n",
      "Author: Due_Brush_3047 | Title: Robinhood Took options away? | Score: 4 | Number of comments: 8 | URL: https://www.reddit.com/r/TSLA/comments/wwykpp/robinhood_took_options_away/\n",
      "\n",
      "Author: _myke | Title: HOLDR... European sell-off means bounce here? | Score: 4 | Number of comments: 2 | URL: https://www.reddit.com/r/TSLA/comments/wuucm0/holdr_european_selloff_means_bounce_here/\n",
      "\n",
      "Author: wewewawa | Title: How Silicon Valley Failed to Fix Transportation | Score: 4 | Number of comments: 2 | URL: https://gizmodo.com/silicon-valleys-transportation-failures-tesla-waymo-bir-1849382788\n",
      "\n",
      "Author: DentistSuch153 | Title: will Tesla run up tomorrow or down | Score: 4 | Number of comments: 15 | URL: https://www.reddit.com/r/TSLA/comments/wr1tc6/will_tesla_run_up_tomorrow_or_down/\n",
      "\n",
      "Author: Also_plus | Title: Tsla Split Question | Score: 3 | Number of comments: 7 | URL: https://www.reddit.com/r/TSLA/comments/wyfy65/tsla_split_question/\n",
      "\n",
      "Author: EqualFlower | Title: Record Date | Score: 3 | Number of comments: 8 | URL: https://www.reddit.com/r/TSLA/comments/wr08ig/record_date/\n",
      "\n",
      "Author: SouthernOar | Title: What will be the new strike price of my $895 options after split? | Score: 2 | Number of comments: 4 | URL: https://www.reddit.com/r/TSLA/comments/wwn6jb/what_will_be_the_new_strike_price_of_my_895/\n",
      "\n",
      "Author: Samnyc007 | Title: Tesla | Score: 2 | Number of comments: 0 | URL: https://www.reddit.com/r/TSLA/comments/wrm8cf/tesla/\n",
      "\n",
      "Author: localbrada | Title: Core Lithium extends offtake term sheet with Tesla | Score: 1 | Number of comments: 0 | URL: https://www.proactiveinvestors.com.au/companies/news/991160/core-lithium-extends-offtake-term-sheet-with-tesla-991160.html\n",
      "\n",
      "Author: BelmontMan | Title: First time owner. Need help | Score: 1 | Number of comments: 17 | URL: https://www.reddit.com/r/TSLA/comments/x02sw5/first_time_owner_need_help/\n",
      "\n",
      "Author: PolarBearPolo | Title: Trading Tesla Daily? | Score: 0 | Number of comments: 5 | URL: https://www.reddit.com/r/TSLA/comments/wxv1j3/trading_tesla_daily/\n",
      "\n",
      "Author: sky_porkchop | Title: Is it too late? | Score: 0 | Number of comments: 10 | URL: https://www.reddit.com/r/TSLA/comments/wxebz8/is_it_too_late/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for submission in subreddit.top(time_filter=\"month\"):\n",
    "\n",
    "    print(\"Author:\", submission.author, \"|\", \"Title:\", \n",
    "          submission.title, \"|\", \"Score:\", submission.score, \n",
    "          \"|\", \"Number of comments:\", submission.num_comments,\n",
    "         \"|\", \"URL:\", submission.url)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "6. Does there seem to be a large distribution of posters or a smaller concentration of posters who are very active? What kind of impact might this have on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 52 above listed submissions from the past month as reference,\n",
    "# 2 posters account for about 40% of all submissions.\n",
    "# Here are their names and number of submissions in the last month:\n",
    "# wewewava (13) and localbrada (8).\n",
    "\n",
    "# This certainly increases the chance the data will be biased since the\n",
    "# conversation is largely influenced by very few people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "c57794392b841cffd8686d5c4548e4e2ec78521f49300d60954d1380f1b4bd1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
